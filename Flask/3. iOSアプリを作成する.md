# 1. 仮想環境の追加
* 仮想環境を追加し、tensorflow==1.5.0/keras==2.1.0 をインストールする
* その後animal_cnn_aug.pyを実行する

# 2. モデルファイルの変換
* .h5ファイルを coremltools というライブラリを使ってmlmodel形式に変換する

# 3. CoreML Toolsのインストールと変換の実行
* python3.6 の環境を作り、pip install coremltools
* conda install keras tensorflow

# 4. Xcode上でプロジェクトを追加
* Xcodeをインストールする
* 新しいプロジェクトを作る
* Language : Swift

# 5. UIパーツを追加
* ImaveViewを追加 : 画像を表示
* TextViewを追加 : 判定結果を表示
* Buttonを追加

# 6. IBOutletとIBActionを関連付ける
* ImageView: 画像を表示する為IBOutletと関連付ける
* TextView: テキストを表示する為IBOutletと関連付ける
* Button: 写真を撮るため、IBActionと関連付ける

# 7. カメラアクセスを許可する設定を行う
* info.plist ⇒ Privacy- Camera Usage Description を選択し、カメラへアクセスできるようになる

# 8. カメラを起動するコードを追加
* UIImagePickerControllerDelegate, UINavigationControllerDelegate という2つのクラスを追加
* カメラを起動するコードと、画像を表示するコードを追加する

# 9. ビルドして実機で実行する
* Build and Run を押す ⇒ 写真を撮るを押すとカメラが起動される ⇒ 写真を撮るとアプリ上に表示されることを確認

# 10. モデルを読み込んで推論を実行
* コードに推定処理を追加する
    * 関数に画像を渡す
    * 関数の処理を追加
        * モデルを読み込み
* コードに判定処理を追加する
    * 判定結果をTextViewに表示する