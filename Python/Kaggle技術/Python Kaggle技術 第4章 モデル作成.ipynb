{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第4章 モデル作成\n",
    "### 4.1.2 モデル作成の流れ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cancer=load_breast_cancer()\n",
    "X=cancer.data\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1       2       3        4        5        6        7       8   \\\n",
       "0    17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010  0.14710  0.2419   \n",
       "1    20.57  17.77  132.90  1326.0  0.08474  0.07864  0.08690  0.07017  0.1812   \n",
       "2    19.69  21.25  130.00  1203.0  0.10960  0.15990  0.19740  0.12790  0.2069   \n",
       "3    11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140  0.10520  0.2597   \n",
       "4    20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800  0.10430  0.1809   \n",
       "..     ...    ...     ...     ...      ...      ...      ...      ...     ...   \n",
       "564  21.56  22.39  142.00  1479.0  0.11100  0.11590  0.24390  0.13890  0.1726   \n",
       "565  20.13  28.25  131.20  1261.0  0.09780  0.10340  0.14400  0.09791  0.1752   \n",
       "566  16.60  28.08  108.30   858.1  0.08455  0.10230  0.09251  0.05302  0.1590   \n",
       "567  20.60  29.33  140.10  1265.0  0.11780  0.27700  0.35140  0.15200  0.2397   \n",
       "568   7.76  24.54   47.92   181.0  0.05263  0.04362  0.00000  0.00000  0.1587   \n",
       "\n",
       "          9   ...      20     21      22      23       24       25      26  \\\n",
       "0    0.07871  ...  25.380  17.33  184.60  2019.0  0.16220  0.66560  0.7119   \n",
       "1    0.05667  ...  24.990  23.41  158.80  1956.0  0.12380  0.18660  0.2416   \n",
       "2    0.05999  ...  23.570  25.53  152.50  1709.0  0.14440  0.42450  0.4504   \n",
       "3    0.09744  ...  14.910  26.50   98.87   567.7  0.20980  0.86630  0.6869   \n",
       "4    0.05883  ...  22.540  16.67  152.20  1575.0  0.13740  0.20500  0.4000   \n",
       "..       ...  ...     ...    ...     ...     ...      ...      ...     ...   \n",
       "564  0.05623  ...  25.450  26.40  166.10  2027.0  0.14100  0.21130  0.4107   \n",
       "565  0.05533  ...  23.690  38.25  155.00  1731.0  0.11660  0.19220  0.3215   \n",
       "566  0.05648  ...  18.980  34.12  126.70  1124.0  0.11390  0.30940  0.3403   \n",
       "567  0.07016  ...  25.740  39.42  184.60  1821.0  0.16500  0.86810  0.9387   \n",
       "568  0.05884  ...   9.456  30.37   59.16   268.6  0.08996  0.06444  0.0000   \n",
       "\n",
       "         27      28       29  \n",
       "0    0.2654  0.4601  0.11890  \n",
       "1    0.1860  0.2750  0.08902  \n",
       "2    0.2430  0.3613  0.08758  \n",
       "3    0.2575  0.6638  0.17300  \n",
       "4    0.1625  0.2364  0.07678  \n",
       "..      ...     ...      ...  \n",
       "564  0.2216  0.2060  0.07115  \n",
       "565  0.1628  0.2572  0.06637  \n",
       "566  0.1418  0.2218  0.07820  \n",
       "567  0.2650  0.4087  0.12400  \n",
       "568  0.0000  0.2871  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=cancer.target\n",
    "import pandas as pd\n",
    "df_x=pd.DataFrame(X)\n",
    "df_y=pd.DataFrame(y)\n",
    "df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2473576315972914\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "\n",
    "scores=[]\n",
    "kf=KFold(n_splits=4,shuffle=True,random_state=71)\n",
    "for tr_idx,va_idx in (kf.split(df_x)):\n",
    "    tr_x,va_x=df_x.iloc[tr_idx],df_x.iloc[va_idx]\n",
    "    tr_y,va_y=df_y.iloc[tr_idx],df_y.iloc[va_idx]\n",
    "    \n",
    "    model=DecisionTreeClassifier()\n",
    "    model.fit(tr_x,tr_y)\n",
    "    va_pred=model.predict(va_x)\n",
    "    score=log_loss(va_y,va_pred)\n",
    "    scores.append(score)\n",
    "\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.4 GBDTの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:42:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { randomstate, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.01409\teval-error:0.02797\n",
      "[1]\ttrain-error:0.00704\teval-error:0.02098\n",
      "[2]\ttrain-error:0.00704\teval-error:0.02797\n",
      "[3]\ttrain-error:0.00470\teval-error:0.02098\n",
      "[4]\ttrain-error:0.00235\teval-error:0.02098\n",
      "[5]\ttrain-error:0.00235\teval-error:0.02797\n",
      "[6]\ttrain-error:0.00235\teval-error:0.02797\n",
      "[7]\ttrain-error:0.00470\teval-error:0.02098\n",
      "[8]\ttrain-error:0.00235\teval-error:0.02098\n",
      "[9]\ttrain-error:0.00235\teval-error:0.02098\n",
      "[10]\ttrain-error:0.00235\teval-error:0.02098\n",
      "[11]\ttrain-error:0.00235\teval-error:0.02098\n",
      "[12]\ttrain-error:0.00235\teval-error:0.02098\n",
      "[13]\ttrain-error:0.00235\teval-error:0.02098\n",
      "[14]\ttrain-error:0.00235\teval-error:0.02098\n",
      "[15]\ttrain-error:0.00235\teval-error:0.02797\n",
      "[16]\ttrain-error:0.00235\teval-error:0.02797\n",
      "[17]\ttrain-error:0.00000\teval-error:0.02797\n",
      "[18]\ttrain-error:0.00000\teval-error:0.02797\n",
      "[19]\ttrain-error:0.00000\teval-error:0.02797\n",
      "logloss:0.10659943121628693\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "#特徴量と目的変数をxgboostのデータ構造に変換する\n",
    "dtrain=xgb.DMatrix(X_train,label=y_train)\n",
    "dvalid=xgb.DMatrix(X_test,label=y_test)\n",
    "\n",
    "#ハイパーパラメータの設定\n",
    "params={'objective':'binary:logistic','silent':1,'randomstate':71}\n",
    "num_round=20\n",
    "\n",
    "#学習の実行\n",
    "#バリデーションデータもモデルに渡し、学習の進行とともにスコアがどう変わるかモニタリングする\n",
    "#watchlistには学習データおよびバリデーションデータをセットする\n",
    "watchlist=[(dtrain,'train'),(dvalid,'eval')]\n",
    "model=xgb.train(params,dtrain,num_round,evals=watchlist)\n",
    "\n",
    "#バリデーションデータでのスコアの確認\n",
    "va_pred=model.predict(dvalid)\n",
    "score=log_loss(y_test,va_pred)\n",
    "print('logloss:{}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:13:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { randomstate, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-logloss:0.46486\teval-logloss:0.48718\n",
      "Multiple eval metrics have been passed: 'eval-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-logloss hasn't improved in 5 rounds.\n",
      "[1]\ttrain-logloss:0.33325\teval-logloss:0.37689\n",
      "[2]\ttrain-logloss:0.24881\teval-logloss:0.30256\n",
      "[3]\ttrain-logloss:0.19045\teval-logloss:0.24353\n",
      "[4]\ttrain-logloss:0.14932\teval-logloss:0.20883\n",
      "[5]\ttrain-logloss:0.12070\teval-logloss:0.18507\n",
      "[6]\ttrain-logloss:0.09843\teval-logloss:0.15989\n",
      "[7]\ttrain-logloss:0.08184\teval-logloss:0.14628\n",
      "[8]\ttrain-logloss:0.06934\teval-logloss:0.13186\n",
      "[9]\ttrain-logloss:0.05997\teval-logloss:0.12048\n",
      "[10]\ttrain-logloss:0.05070\teval-logloss:0.11578\n",
      "[11]\ttrain-logloss:0.04411\teval-logloss:0.11234\n",
      "[12]\ttrain-logloss:0.03848\teval-logloss:0.10946\n",
      "[13]\ttrain-logloss:0.03422\teval-logloss:0.10251\n",
      "[14]\ttrain-logloss:0.03084\teval-logloss:0.10035\n",
      "[15]\ttrain-logloss:0.02807\teval-logloss:0.09922\n",
      "[16]\ttrain-logloss:0.02495\teval-logloss:0.09547\n",
      "[17]\ttrain-logloss:0.02251\teval-logloss:0.09246\n",
      "[18]\ttrain-logloss:0.02108\teval-logloss:0.08755\n",
      "[19]\ttrain-logloss:0.01983\teval-logloss:0.08540\n",
      "[20]\ttrain-logloss:0.01816\teval-logloss:0.08622\n",
      "[21]\ttrain-logloss:0.01695\teval-logloss:0.08398\n",
      "[22]\ttrain-logloss:0.01604\teval-logloss:0.08456\n",
      "[23]\ttrain-logloss:0.01546\teval-logloss:0.08117\n",
      "[24]\ttrain-logloss:0.01455\teval-logloss:0.07900\n",
      "[25]\ttrain-logloss:0.01410\teval-logloss:0.08069\n",
      "[26]\ttrain-logloss:0.01360\teval-logloss:0.07765\n",
      "[27]\ttrain-logloss:0.01300\teval-logloss:0.07797\n",
      "[28]\ttrain-logloss:0.01253\teval-logloss:0.07883\n",
      "[29]\ttrain-logloss:0.01221\teval-logloss:0.08048\n",
      "[30]\ttrain-logloss:0.01187\teval-logloss:0.08027\n",
      "[31]\ttrain-logloss:0.01149\teval-logloss:0.07705\n",
      "[32]\ttrain-logloss:0.01122\teval-logloss:0.07587\n",
      "[33]\ttrain-logloss:0.01092\teval-logloss:0.07723\n",
      "[34]\ttrain-logloss:0.01055\teval-logloss:0.07703\n",
      "[35]\ttrain-logloss:0.01021\teval-logloss:0.07566\n",
      "[36]\ttrain-logloss:0.00997\teval-logloss:0.07326\n",
      "[37]\ttrain-logloss:0.00973\teval-logloss:0.07483\n",
      "[38]\ttrain-logloss:0.00953\teval-logloss:0.07463\n",
      "[39]\ttrain-logloss:0.00933\teval-logloss:0.07395\n",
      "[40]\ttrain-logloss:0.00912\teval-logloss:0.07172\n",
      "[41]\ttrain-logloss:0.00895\teval-logloss:0.07319\n",
      "[42]\ttrain-logloss:0.00874\teval-logloss:0.07120\n",
      "[43]\ttrain-logloss:0.00857\teval-logloss:0.06917\n",
      "[44]\ttrain-logloss:0.00842\teval-logloss:0.06931\n",
      "[45]\ttrain-logloss:0.00827\teval-logloss:0.06960\n",
      "[46]\ttrain-logloss:0.00820\teval-logloss:0.06986\n",
      "[47]\ttrain-logloss:0.00808\teval-logloss:0.06969\n",
      "[48]\ttrain-logloss:0.00799\teval-logloss:0.06928\n",
      "Stopping. Best iteration:\n",
      "[43]\ttrain-logloss:0.00857\teval-logloss:0.06917\n",
      "\n",
      "logloss:0.06928174767640771\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "#特徴量と目的変数をxgboostのデータ構造に変換する\n",
    "dtrain=xgb.DMatrix(X_train,label=y_train)\n",
    "dvalid=xgb.DMatrix(X_test,label=y_test)\n",
    "dtest=xgb.DMatrix(X,label=y)\n",
    "\n",
    "#ハイパーパラメータの設定\n",
    "params={'objective':'binary:logistic','silent':1,'randomstate':71,'eval_metric':'logloss'}\n",
    "num_round=500\n",
    "\n",
    "#学習の実行\n",
    "#バリデーションデータもモデルに渡し、学習の進行とともにスコアがどう変わるかモニタリングする\n",
    "#watchlistには学習データおよびバリデーションデータをセットする\n",
    "watchlist=[(dtrain,'train'),(dvalid,'eval')]\n",
    "model=xgb.train(params,dtrain,num_round,evals=watchlist,early_stopping_rounds=5) #early_stopping_rounds分だけ様子を見る\n",
    "\n",
    "#バリデーションデータでのスコアの確認\n",
    "va_pred=model.predict(dvalid)\n",
    "score=log_loss(y_test,va_pred)\n",
    "print('logloss:{}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#予測するときは、early stoppingを行った場合n_tree_limitパラメータを設定する\n",
    "pred=model.predict(dtest,ntree_limit=model.best_ntree_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain's binary_logloss: 0.570148\tvalid's binary_logloss: 0.60288\n",
      "[2]\ttrain's binary_logloss: 0.504462\tvalid's binary_logloss: 0.540086\n",
      "[3]\ttrain's binary_logloss: 0.452677\tvalid's binary_logloss: 0.487231\n",
      "[4]\ttrain's binary_logloss: 0.409785\tvalid's binary_logloss: 0.441593\n",
      "[5]\ttrain's binary_logloss: 0.373453\tvalid's binary_logloss: 0.402942\n",
      "[6]\ttrain's binary_logloss: 0.338981\tvalid's binary_logloss: 0.372401\n",
      "[7]\ttrain's binary_logloss: 0.311156\tvalid's binary_logloss: 0.342663\n",
      "[8]\ttrain's binary_logloss: 0.2851\tvalid's binary_logloss: 0.31745\n",
      "[9]\ttrain's binary_logloss: 0.2615\tvalid's binary_logloss: 0.297295\n",
      "[10]\ttrain's binary_logloss: 0.242534\tvalid's binary_logloss: 0.277161\n",
      "[11]\ttrain's binary_logloss: 0.224498\tvalid's binary_logloss: 0.261777\n",
      "[12]\ttrain's binary_logloss: 0.207652\tvalid's binary_logloss: 0.247412\n",
      "[13]\ttrain's binary_logloss: 0.194299\tvalid's binary_logloss: 0.232947\n",
      "[14]\ttrain's binary_logloss: 0.180114\tvalid's binary_logloss: 0.221554\n",
      "[15]\ttrain's binary_logloss: 0.167555\tvalid's binary_logloss: 0.211101\n",
      "[16]\ttrain's binary_logloss: 0.156362\tvalid's binary_logloss: 0.202408\n",
      "[17]\ttrain's binary_logloss: 0.146447\tvalid's binary_logloss: 0.19389\n",
      "[18]\ttrain's binary_logloss: 0.137196\tvalid's binary_logloss: 0.185465\n",
      "[19]\ttrain's binary_logloss: 0.12868\tvalid's binary_logloss: 0.178788\n",
      "[20]\ttrain's binary_logloss: 0.120472\tvalid's binary_logloss: 0.172052\n",
      "[21]\ttrain's binary_logloss: 0.113211\tvalid's binary_logloss: 0.165629\n",
      "[22]\ttrain's binary_logloss: 0.106115\tvalid's binary_logloss: 0.161116\n",
      "[23]\ttrain's binary_logloss: 0.100168\tvalid's binary_logloss: 0.156018\n",
      "[24]\ttrain's binary_logloss: 0.093827\tvalid's binary_logloss: 0.150409\n",
      "[25]\ttrain's binary_logloss: 0.0884127\tvalid's binary_logloss: 0.147263\n",
      "[26]\ttrain's binary_logloss: 0.0830114\tvalid's binary_logloss: 0.142008\n",
      "[27]\ttrain's binary_logloss: 0.0782494\tvalid's binary_logloss: 0.137326\n",
      "[28]\ttrain's binary_logloss: 0.0734787\tvalid's binary_logloss: 0.132763\n",
      "[29]\ttrain's binary_logloss: 0.0691179\tvalid's binary_logloss: 0.127159\n",
      "[30]\ttrain's binary_logloss: 0.0653533\tvalid's binary_logloss: 0.123462\n",
      "[31]\ttrain's binary_logloss: 0.0610597\tvalid's binary_logloss: 0.121103\n",
      "[32]\ttrain's binary_logloss: 0.0577164\tvalid's binary_logloss: 0.117809\n",
      "[33]\ttrain's binary_logloss: 0.0537386\tvalid's binary_logloss: 0.114659\n",
      "[34]\ttrain's binary_logloss: 0.0506373\tvalid's binary_logloss: 0.110411\n",
      "[35]\ttrain's binary_logloss: 0.0473146\tvalid's binary_logloss: 0.106133\n",
      "[36]\ttrain's binary_logloss: 0.0442915\tvalid's binary_logloss: 0.104155\n",
      "[37]\ttrain's binary_logloss: 0.0419079\tvalid's binary_logloss: 0.100527\n",
      "[38]\ttrain's binary_logloss: 0.0394986\tvalid's binary_logloss: 0.0993109\n",
      "[39]\ttrain's binary_logloss: 0.0370938\tvalid's binary_logloss: 0.0971998\n",
      "[40]\ttrain's binary_logloss: 0.0350267\tvalid's binary_logloss: 0.0958955\n",
      "[41]\ttrain's binary_logloss: 0.0332988\tvalid's binary_logloss: 0.0930232\n",
      "[42]\ttrain's binary_logloss: 0.03102\tvalid's binary_logloss: 0.0904024\n",
      "[43]\ttrain's binary_logloss: 0.0288269\tvalid's binary_logloss: 0.0887249\n",
      "[44]\ttrain's binary_logloss: 0.0272467\tvalid's binary_logloss: 0.0859047\n",
      "[45]\ttrain's binary_logloss: 0.0252032\tvalid's binary_logloss: 0.0839897\n",
      "[46]\ttrain's binary_logloss: 0.0236158\tvalid's binary_logloss: 0.0837016\n",
      "[47]\ttrain's binary_logloss: 0.0219825\tvalid's binary_logloss: 0.0820462\n",
      "[48]\ttrain's binary_logloss: 0.0206149\tvalid's binary_logloss: 0.0791812\n",
      "[49]\ttrain's binary_logloss: 0.0193916\tvalid's binary_logloss: 0.0784567\n",
      "[50]\ttrain's binary_logloss: 0.018138\tvalid's binary_logloss: 0.0768721\n",
      "[51]\ttrain's binary_logloss: 0.0170469\tvalid's binary_logloss: 0.0764574\n",
      "[52]\ttrain's binary_logloss: 0.0161024\tvalid's binary_logloss: 0.0760438\n",
      "[53]\ttrain's binary_logloss: 0.0151142\tvalid's binary_logloss: 0.073252\n",
      "[54]\ttrain's binary_logloss: 0.0141361\tvalid's binary_logloss: 0.0717242\n",
      "[55]\ttrain's binary_logloss: 0.0132291\tvalid's binary_logloss: 0.070834\n",
      "[56]\ttrain's binary_logloss: 0.0123669\tvalid's binary_logloss: 0.0684154\n",
      "[57]\ttrain's binary_logloss: 0.0117429\tvalid's binary_logloss: 0.0673613\n",
      "[58]\ttrain's binary_logloss: 0.011052\tvalid's binary_logloss: 0.0680312\n",
      "[59]\ttrain's binary_logloss: 0.0103981\tvalid's binary_logloss: 0.0658356\n",
      "[60]\ttrain's binary_logloss: 0.00966967\tvalid's binary_logloss: 0.0654275\n",
      "[61]\ttrain's binary_logloss: 0.00920833\tvalid's binary_logloss: 0.0653013\n",
      "[62]\ttrain's binary_logloss: 0.00865541\tvalid's binary_logloss: 0.0655867\n",
      "[63]\ttrain's binary_logloss: 0.0081814\tvalid's binary_logloss: 0.0666877\n",
      "[64]\ttrain's binary_logloss: 0.00772696\tvalid's binary_logloss: 0.0646669\n",
      "[65]\ttrain's binary_logloss: 0.00725565\tvalid's binary_logloss: 0.0638792\n",
      "[66]\ttrain's binary_logloss: 0.00684304\tvalid's binary_logloss: 0.0643543\n",
      "[67]\ttrain's binary_logloss: 0.00647105\tvalid's binary_logloss: 0.0641082\n",
      "[68]\ttrain's binary_logloss: 0.00610515\tvalid's binary_logloss: 0.0641473\n",
      "[69]\ttrain's binary_logloss: 0.00571513\tvalid's binary_logloss: 0.0655921\n",
      "[70]\ttrain's binary_logloss: 0.00541539\tvalid's binary_logloss: 0.0669397\n",
      "[71]\ttrain's binary_logloss: 0.00511627\tvalid's binary_logloss: 0.0680544\n",
      "[72]\ttrain's binary_logloss: 0.00481477\tvalid's binary_logloss: 0.0681666\n",
      "[73]\ttrain's binary_logloss: 0.00451639\tvalid's binary_logloss: 0.0661701\n",
      "[74]\ttrain's binary_logloss: 0.00428823\tvalid's binary_logloss: 0.0667541\n",
      "[75]\ttrain's binary_logloss: 0.00404794\tvalid's binary_logloss: 0.066337\n",
      "[76]\ttrain's binary_logloss: 0.00387271\tvalid's binary_logloss: 0.0665028\n",
      "[77]\ttrain's binary_logloss: 0.00365132\tvalid's binary_logloss: 0.0635946\n",
      "[78]\ttrain's binary_logloss: 0.0034029\tvalid's binary_logloss: 0.0626194\n",
      "[79]\ttrain's binary_logloss: 0.00318254\tvalid's binary_logloss: 0.0628736\n",
      "[80]\ttrain's binary_logloss: 0.00302957\tvalid's binary_logloss: 0.0634\n",
      "[81]\ttrain's binary_logloss: 0.00286387\tvalid's binary_logloss: 0.0635115\n",
      "[82]\ttrain's binary_logloss: 0.00274206\tvalid's binary_logloss: 0.0656734\n",
      "[83]\ttrain's binary_logloss: 0.00258883\tvalid's binary_logloss: 0.065897\n",
      "[84]\ttrain's binary_logloss: 0.0024073\tvalid's binary_logloss: 0.0665256\n",
      "[85]\ttrain's binary_logloss: 0.00227068\tvalid's binary_logloss: 0.0662146\n",
      "[86]\ttrain's binary_logloss: 0.0021406\tvalid's binary_logloss: 0.067206\n",
      "[87]\ttrain's binary_logloss: 0.00201728\tvalid's binary_logloss: 0.0678465\n",
      "[88]\ttrain's binary_logloss: 0.00191855\tvalid's binary_logloss: 0.0695398\n",
      "[89]\ttrain's binary_logloss: 0.00181302\tvalid's binary_logloss: 0.0696414\n",
      "[90]\ttrain's binary_logloss: 0.00170445\tvalid's binary_logloss: 0.0676501\n",
      "[91]\ttrain's binary_logloss: 0.00159632\tvalid's binary_logloss: 0.0684323\n",
      "[92]\ttrain's binary_logloss: 0.00150467\tvalid's binary_logloss: 0.0695522\n",
      "[93]\ttrain's binary_logloss: 0.00140932\tvalid's binary_logloss: 0.0701319\n",
      "[94]\ttrain's binary_logloss: 0.00134843\tvalid's binary_logloss: 0.0724273\n",
      "[95]\ttrain's binary_logloss: 0.00125615\tvalid's binary_logloss: 0.072109\n",
      "[96]\ttrain's binary_logloss: 0.00119056\tvalid's binary_logloss: 0.072083\n",
      "[97]\ttrain's binary_logloss: 0.00113153\tvalid's binary_logloss: 0.0716813\n",
      "[98]\ttrain's binary_logloss: 0.0010699\tvalid's binary_logloss: 0.0723732\n",
      "[99]\ttrain's binary_logloss: 0.00100957\tvalid's binary_logloss: 0.0730866\n",
      "[100]\ttrain's binary_logloss: 0.000942869\tvalid's binary_logloss: 0.0730977\n",
      "logloss:0.07309769383633415\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "#特徴量と目的変数をlgbのデータ構造に変換する\n",
    "lgb_train=lgb.Dataset(X_train,y_train)\n",
    "lgb_eval=lgb.Dataset(X_test,y_test)\n",
    "\n",
    "#ハイパーパラメータの設定\n",
    "params={'objective':'binary','seed':71,'vervose':0,'metrics':'binary_logloss'}\n",
    "num_round=100\n",
    "\n",
    "#学習の実行\n",
    "#カテゴリ変数をパラメータで指定している\n",
    "#categorical_features={'product','medical_info_b2','medical_info_b3'}\n",
    "watchlist=[(dtrain,'train'),(dvalid,'eval')]\n",
    "model=lgb.train(params,lgb_train,num_boost_round=num_round,\n",
    "#                categorical_feature=categorical_features,\n",
    "                valid_names=['train','valid'],valid_sets=[lgb_train,lgb_eval])\n",
    "\n",
    "#バリデーションデータでのスコアの確認\n",
    "va_pred=model.predict(X_test)\n",
    "score=log_loss(y_test,va_pred)\n",
    "print('logloss:{}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.4 ニューラルネットの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.2.0-cp37-cp37m-win_amd64.whl (459.2 MB)\n",
      "Collecting astunparse==1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting keras-preprocessing>=1.1.0\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.2.1-py3-none-any.whl (63 kB)\n",
      "Collecting protobuf>=3.8.0\n",
      "  Downloading protobuf-3.12.2-cp37-cp37m-win_amd64.whl (1.0 MB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\nakam\\anaconda3_1\\lib\\site-packages (from tensorflow) (1.14.0)\n",
      "Collecting google-pasta>=0.1.8\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in c:\\users\\nakam\\anaconda3_1\\lib\\site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\users\\nakam\\anaconda3_1\\lib\\site-packages (from tensorflow) (1.18.1)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in c:\\users\\nakam\\anaconda3_1\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Collecting absl-py>=0.7.0\n",
      "  Downloading absl-py-0.9.0.tar.gz (104 kB)\n",
      "Collecting tensorflow-estimator<2.3.0,>=2.2.0\n",
      "  Downloading tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454 kB)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in c:\\users\\nakam\\anaconda3_1\\lib\\site-packages (from tensorflow) (1.4.1)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting tensorboard<2.3.0,>=2.2.0\n",
      "  Downloading tensorboard-2.2.2-py3-none-any.whl (3.0 MB)\n",
      "Collecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.30.0-cp37-cp37m-win_amd64.whl (2.3 MB)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\nakam\\anaconda3_1\\lib\\site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nakam\\anaconda3_1\\lib\\site-packages (from protobuf>=3.8.0->tensorflow) (45.2.0.post20200210)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\nakam\\anaconda3_1\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\nakam\\anaconda3_1\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.0)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.18.0-py2.py3-none-any.whl (90 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.2.2-py3-none-any.whl (88 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\nakam\\anaconda3_1\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\nakam\\anaconda3_1\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.25.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\nakam\\anaconda3_1\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nakam\\anaconda3_1\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2019.11.28)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.1.1-py3-none-any.whl (10 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3\"\n",
      "  Downloading rsa-4.6-py3-none-any.whl (47 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\users\\nakam\\anaconda3_1\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.5.0)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\nakam\\anaconda3_1\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.2.0)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Building wheels for collected packages: absl-py, termcolor\n",
      "  Building wheel for absl-py (setup.py): started\n",
      "  Building wheel for absl-py (setup.py): finished with status 'done'\n",
      "  Created wheel for absl-py: filename=absl_py-0.9.0-py3-none-any.whl size=121935 sha256=b8cf57d1f135112ac959fe5d285e578091aec07c59d967b5e0498d21b953ef8f\n",
      "  Stored in directory: c:\\users\\nakam\\appdata\\local\\pip\\cache\\wheels\\cc\\af\\1a\\498a24d0730ef484019e007bb9e8cef3ac00311a672c049a3e\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4835 sha256=4e8636ea4f493275348ddeeff63c814f089b64641b4e064e33311f615d401799\n",
      "  Stored in directory: c:\\users\\nakam\\appdata\\local\\pip\\cache\\wheels\\3f\\e3\\ec\\8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
      "Successfully built absl-py termcolor\n",
      "Installing collected packages: astunparse, keras-preprocessing, gast, opt-einsum, protobuf, google-pasta, absl-py, tensorflow-estimator, termcolor, grpcio, cachetools, pyasn1, rsa, pyasn1-modules, google-auth, tensorboard-plugin-wit, markdown, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed absl-py-0.9.0 astunparse-1.6.3 cachetools-4.1.1 gast-0.3.3 google-auth-1.18.0 google-auth-oauthlib-0.4.1 google-pasta-0.2.0 grpcio-1.30.0 keras-preprocessing-1.1.2 markdown-3.2.2 oauthlib-3.1.0 opt-einsum-3.2.1 protobuf-3.12.2 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.6 tensorboard-2.2.2 tensorboard-plugin-wit-1.7.0 tensorflow-2.2.0 tensorflow-estimator-2.2.0 termcolor-1.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(10054, '既存の接続はリモート ホストに強制的に切断されました。', None, 10054, None))': /simple/astunparse/\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cancer=load_breast_cancer()\n",
    "X=cancer.data\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "tr_x,test_x,tr_y,test_y=train_test_split(X,y)\n",
    "tr_x,va_x,tr_y,va_y=train_test_split(tr_x,tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.5739 - accuracy: 0.7900 - val_loss: 0.3420 - val_accuracy: 0.9252\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3231 - accuracy: 0.9530 - val_loss: 0.2216 - val_accuracy: 0.9346\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.2030 - accuracy: 0.9561 - val_loss: 0.1692 - val_accuracy: 0.9439\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1474 - accuracy: 0.9624 - val_loss: 0.1462 - val_accuracy: 0.9439\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1210 - accuracy: 0.9592 - val_loss: 0.1322 - val_accuracy: 0.9439\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1029 - accuracy: 0.9624 - val_loss: 0.1211 - val_accuracy: 0.9439\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0859 - accuracy: 0.9749 - val_loss: 0.1143 - val_accuracy: 0.9626\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0716 - accuracy: 0.9781 - val_loss: 0.1094 - val_accuracy: 0.9720\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0665 - accuracy: 0.9781 - val_loss: 0.1063 - val_accuracy: 0.9813\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0551 - accuracy: 0.9812 - val_loss: 0.1049 - val_accuracy: 0.9813\n",
      "0.10492530413286208\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#データのスケーリング\n",
    "scaler=StandardScaler()\n",
    "tr_x=scaler.fit_transform(tr_x)\n",
    "va_x=scaler.transform(va_x)\n",
    "test_x=scaler.transform(test_x)\n",
    "\n",
    "#ニューラルネットモデルの構築\n",
    "model=Sequential()\n",
    "model.add(Dense(256,activation='relu',input_shape=(tr_x.shape[1],))) #1層目が256個のノードからなる\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "#学習の実行\n",
    "#validationデータもモデルに渡し、学習の進行とともにスコアがどう変わるかモニタリングする\n",
    "batch_size=128\n",
    "epochs=10\n",
    "history=model.fit(tr_x,tr_y,\n",
    "                 batch_size=batch_size,epochs=epochs,\n",
    "                 verbose=1,validation_data=(va_x,va_y))\n",
    "\n",
    "#validationデータでのスコアの確認\n",
    "va_pred=model.predict(va_x)\n",
    "score=log_loss(va_y,va_pred,eps=1e-7)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0530 - accuracy: 0.9812 - val_loss: 0.1046 - val_accuracy: 0.9813\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0478 - accuracy: 0.9843 - val_loss: 0.1050 - val_accuracy: 0.9813\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0449 - accuracy: 0.9875 - val_loss: 0.1049 - val_accuracy: 0.9813\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0420 - accuracy: 0.9875 - val_loss: 0.1045 - val_accuracy: 0.9813\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0377 - accuracy: 0.9843 - val_loss: 0.1044 - val_accuracy: 0.9813\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0376 - accuracy: 0.9906 - val_loss: 0.1044 - val_accuracy: 0.9813\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0355 - accuracy: 0.9906 - val_loss: 0.1043 - val_accuracy: 0.9813\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0305 - accuracy: 0.9937 - val_loss: 0.1046 - val_accuracy: 0.9907\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0316 - accuracy: 0.9937 - val_loss: 0.1054 - val_accuracy: 0.9907\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0287 - accuracy: 0.9937 - val_loss: 0.1062 - val_accuracy: 0.9907\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0244 - accuracy: 0.9937 - val_loss: 0.1074 - val_accuracy: 0.9907\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0284 - accuracy: 0.9875 - val_loss: 0.1085 - val_accuracy: 0.9907\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0253 - accuracy: 0.9906 - val_loss: 0.1102 - val_accuracy: 0.9907\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0220 - accuracy: 0.9937 - val_loss: 0.1118 - val_accuracy: 0.9907\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0217 - accuracy: 0.9969 - val_loss: 0.1143 - val_accuracy: 0.9907\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0197 - accuracy: 0.9937 - val_loss: 0.1165 - val_accuracy: 0.9907\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0195 - accuracy: 0.9969 - val_loss: 0.1184 - val_accuracy: 0.9907\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "#アーリーストッピングの観察するroundを20とする\n",
    "#restore_best_weightsを設定することで、最適なエポックのモデルを使用する\n",
    "epochs=50\n",
    "early_stopping=EarlyStopping(monitor='val_loss',patience=10,restore_best_weights=True)\n",
    "\n",
    "history=model.fit(tr_x,tr_y,\n",
    "                 batch_size=batch_size,epochs=epochs,\n",
    "                 verbose=1,validation_data=(va_x,va_y),callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.4 線形モデルの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11196744951332009\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#データのスケーリング\n",
    "scaler=StandardScaler()\n",
    "tr_x=scaler.fit_transform(tr_x)\n",
    "va_x=scaler.transform(va_x)\n",
    "test_x=scaler.transform(test_x)\n",
    "\n",
    "#線形モデルの構築・学習\n",
    "model=LogisticRegression(C=1.0)\n",
    "model.fit(tr_x,tr_y)\n",
    "\n",
    "#validation_dataでのスコアの確認\n",
    "va_pred=model.predict_proba(va_x)\n",
    "score=log_loss(va_y,va_pred)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
