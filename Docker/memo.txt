8.Docker Buildの詳細とその他のInstruction

===8-1============================================================================
【Docker Daemonとは】
DockerはClient-server architectureを採用している
Client：docker buildなどの指示を出すところ
Server：Docker daemonが命令をもとに、オブジェクトを管理する

【Build Contextとは】
Docker build . とするとフォルダ内のデータとDockerファイルからimageを作成する
このフォルダをBuild Contextという。

【Copy】
Build Context内にあるデータをimageに反映して、コンテナ内に作成するために使用する

【Add】
単純にファイル・フォルダをコピーする場合はCOPY
tarの圧縮ファイルをコピーして解凍したい場合はADDを使う
(容量が大きい、階層構造になっている）

tar -cvf compressed.tar sample_folder でsample_folderを圧縮可能

===8-2============================================================================
【DockerfileがBuild Contextにない場合】
docker -f <dockerfilename> <build context>

今回は以下のように実施。
docker build -f ../Dockerfile.dev .

【EntryPointとは】
Docker run時に上書きすることができない。
EntryPointがある場合はCMDは["param1","param2"...]の形をとる。

【Envとは】
ENV <key> <value>
ENV <key> = <value>などで設定する

【Workdir】
それ以降の作業場所を変更する
WORKDIR <PATH>

9. ホストとコンテナの関係を理解する

===9-1===========================================================================
【v-】
docker run -v <host>:<container>　でホストのファイルシステムをコンテナにマウントする
元ファイルをアップデートすると、マウントしているので、アップデートされた状態となる


===9-2===========================================================================
【u-】
-u <user id>:<group id> でユーザーidとグループidを指定してコンテナをrunする

ls -laでファイルの権限が見れる
drwxrwxrwx
 d:ディレクトリ（フォルダであることを示す）
 r:読み取り
 w:書き込み
 x:実行
 d（所有者）（所有グループ）（その他）　となっており、上の例ではすべて可能。


以下はファイルは無し。

【p-】
-p <host_port>:<container_port> でホストのポートをコンテナのポートにつなげる

docker run -it -p 8888:8888 --rm jupyter/datascience-notebook bash
jupyter notebook
⇒ブラウザからlocalhost:8888にアクセス（自分から自分にアクセスする際に使用する）

【--cpus/memory】
--cpus <# of CPUs> :コンテナがアクセスできる上限のCPUを設定
--memory <byte> :コンテナがアクセスできる上限のメモリを設定

1 K byte = 1024 byte
1 M byte = 1024 * 1024 byte

docker run -it --rm --cpus 4 --memory 2g ubuntu bash で上限を設定可能
もう一つcmdを開いて、docker ps を実行しIDを確認
docker inspect <ID> で以下を確認可能　
　"Memory": 2147483648　⇒メモリが2ギガに設定されている(1024**3)
　"NanoCpus": 4000000000 ⇒CPUが4つに設定されている

linuxであれば、grepでcpuという文字が入っているものだけを抽出するのが便利だが、windowsだと不可
　docker inspect 5183dc8ac160 | grep -i cpu



10.Dockerでプロレベルのデータサイエンス環境を作る

===10-1=============================================================================
docker build .
docker run -it <ID> bash　でコンテナを作成
opt に shファイルがあるので、
sh Anaconda～　を実行して、インストールを開始。
途中のインストール先は /opt/anaconda3に指定

echo $PATH　でパスを確認。
export PATH=/opt/anaconda3/bin:$PATH でpathにanacondaを追加可能
　⇒ pythonと打つと起動可能。exit()で抜け出す。

これで環境作成が完了。これを自動でやらないといけない。
sh -x Anaconda～ を実行すると、インストールは開始されずに、オプションを確認可能
　-b でバッチモード　⇒　インタラクティブな操作を回避可能
　-p でインストール先を指定可能
　
===10-2=============================================================================
docker build .
docker run -p 8888:8888 <ID>で Jupyterが起動される
　⇒localhost:8888 でJupyter Labを使用可能

以下のようにすることで、マウントして、mounted_folderを確認可能となる
--name my-lab でコンテナにmy-labという名前を付けている
docker run -p 8888:8888 -v C:/Users/nakam/Desktop/docker/mounted_folder:/work --name my-lab <ID>


11.AWSにデータサイエンス環境を構築する
【sshログイン】
chmod 400 <file>でパーミッションを変更
4:read, 2:write, 1:excute, 0:no permission。
全権限なら4+2+1=7
「所有者」⇒「所有グループ」⇒「その他」の3つを順に指定

cdでフォルダ移動して、
ssh -i mydocker.pem username @ hostname(public DNS)で接続可能
 usernameはdefaultでubuntuになっている
 

【docker install】
sudo apt-get update
sudo apt-get install docker.io

 ⇒ここでsudo docker imagesとすれば、コマンドが使えるが、毎回は面倒

sudo gpasswd -a ubuntu docker #ubuntuというユーザーをdockerに所属させる
 ⇒一度exitして、再度ssh接続すると、コマンドが今まで通り使用可能に

【docker imageのアップロード】
imageが重たい場合に.tarに圧縮してアップロードする方法を試してみる。
サーバーがインターネットにつながらない場合はこの方法。
インターネットにつながる場合は、dockerファイルをアップロードすればよい
　（dockerファイルに書いてあるものをインターネットからダウンロードしながらbuildされる）

①docker build . でimageを作成
②docker save <ID> > myimage.tar でtarファイルに変換
③SFTP（Secure File Transfer Protocol)でログイン
    sftp -i mydocker.pem ubuntu@ec2-13-231-144-154.ap-northeast-1.compute.amazonaws.com
④put myimage.tar /home/ubuntu　で tarファイルを home/ubuntuにアップロード可能
    SFTPにおいてputはアップロード、getはダウンロード

【.tarファイルからimageファイルの作成】
sshログインした後、 docker load < myimage.tar で解凍
docker run -it <ID> sh で実行。
　（今回ubuntuが重たいのでalphineを使っており、bashではなくてshが使用可能）


【docker fileのアップロード】
ネットがつながる環境であればdocker fileをアップロードしてbuildするのが楽

#sftpログインし、dockerfileをアップロード
sftp -i mydocker.pem ubuntu@ec2-54-168-247-143.ap-northeast-1.compute.amazonaws.com
put ../10-2/Dockerfile

#一度exit
exit

#sshログイン
ssh -i mydocker.pem ubuntu@ec2-54-168-247-143.ap-northeast-1.compute.amazonaws.com

#EC2にフォルダを作り、Dockerfileを移動し、build
mkdir dsenv_build
mv Dockerfile dsenv_build
cd dsenv_build
docker build .

しかし容量が足りないので、buildできない
 dockerのオブジェクトは/var/lib/docker/に保存されるので、ここの容量が必要
 AWSのEC2⇒Elastic Block Storeからボリュームを20GBに変更する
 
 再度sshログインして、lsblkで容量確認可能
 反映されないときは以下で確認
 https://qiita.com/t_n/items/0b376269bf7f3b088699

docker run -v ~:/work -p 8888:8888 <ID>　でrunを行う
(workフォルダに dsenv_buildをマウントしている）


http://ec2-54-168-247-143.ap-northeast-1.compute.amazonaws.com:8888　でブラウザで開ける

【コンテナのアクセス権限】
ubuntu は adduserでユーザーを作ることが可能
adduser --uid <userid> <username

sudo adduser --uid 1111 aaa
sudo adduser --uid 2222 bbb

cd /home/aaa でディレクトリができたことを確認
cd .. でhomeに移動して、 ls -la　で書き込み権限を確認
　⇒bbb は aaaに書き込み出来ないことがわかる


#-u 1111 でuserid 1111でログイン
#-v でマウントを実行
docker run -u 1111 -v /home/aaa:/home/aaa -v /home/bbb:/home/bbb -it ubuntu bash
　⇒ ls -laで確認すると bbb に書き込めないことがわかる
  ⇒ cd で bbbに移動して touch test で試すことも可能


12.DockerでGPUを使う

EC2でGPUのインスタンスを作成
SSH接続を実行
　ssh -i mygpukey.pem ubuntu@<Public DNS>

【NVIDIAのgpuを使うためにドライバのインストール】

①Dockerをインストール
 sudo apt-get update 
 sudo apt-get install docker.io #Dockerをインストール
 sudo gpasswd -a ubuntu docker 
 docker --version #versionを確認

②NVIDIAドライバをインストール
 NvidiaのページのPackage Manegers 通りにコマンドを実行
 (https://docs.nvidia.com/datacenter/tesla/tesla-installation-notes/index.html)
 nvidia-smi で今のGPUの状態を確認
　
③nvidia-container-toolkitをインストール
 https://github.com/NVIDIA/nvidia-docker　にある通り、Cuda Toolkitは各コンテナに持つ
　このページの　Setting up NVIDIA Container Toolkit　を実行する

distribution=$(. /etc/os-release;echo $ID$VERSION_ID) \
   && curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add - \
   && curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list

curl -s -L https://nvidia.github.io/nvidia-container-runtime/experimental/$distribution/nvidia-container-runtime.list | sudo tee /etc/apt/sources.list.d/nvidia-container-runtime.list

sudo apt-get update
sudo apt-get install -y nvidia-docker2
sudo systemctl restart docker

この後docker run --gpus all nvidia/cuda:9.0-base nvidia-smi を実行
（Permission deniedになると一度exitして再度sshすれば解決できる）

【GPU用にDockerfileを更新】
　sftp -i mygpukey.pem ubuntu@<Public DNS> #sftp接続
  put -r dsenv_build #dsenv_buildをput(Folderをputする場合は-r)
  
　次にssh接続
　ssh -i mygpukey.pem ubuntu@<Public DNS> #sftp接続

  Dockerfileに以下の変更を加える
  #ubuntu18.04をもとにしたcuda
　　最初の行を以下に変更
　　From nvidia/cuda:10.1-cudnn7-runtime-ubuntu18.04

　#pip upgradeのところを以下に変更
　　Run pip install --upgrade pip && pip install \
    keras==2.3\
    scipy==1.4.1\
    tensorflow-gpu==2.2.1


  vimを使って編集する
　　vim dsenv_build/Dockerfile

    iを押すとinsertモード⇒これで編集し、終わったらescapeボタン
　　⇒:wq! と押すと、ファイルを保存して閉じる。

  cd dsenv_build
  docker build .



13. Docker composeを使って本格的Webアプリ開発環境を構築する

docker-compose --version　で docker-composeが入っていることを確認する。

【Rails】のDockerfileを作成する

【Docker Composeを使用する】
前回までに学んだことを実行するならば以下のようなコードになる。
docker run -v ~/Desktop/product-register:/product-register -p 3000:3000 -it <ID> bash

これがDocker Composeを使うと楽になる
Docker-compose.ymlを作成する

docker build <build contexts> ⇒ docker-compose build
docker run <image> ⇒ docker-compose up
docker ps ⇒ docker-compose ps
docker exec <container> ⇒ docker-compose exec <service>

今回は
docker-compose up -d でbuild+runを行う
docker-compose exec web bash　でコンテナを起動

【Railsのセットアップ】
rails new . --force --databse=postgresql --skip-bundle
 ⇒これを実行すると、gemfileが更新されるので、再度docker-compose upが必要
exit
docker-compose down

#--buildをすることで、もう一度buildから行う
docker-compose up --build -d

docker-compose exec web bash

起動したら
rails s -b 0.0.0.0 でrailsが起動する


【docker-compose.ymlにDB部分を追記する】
docker-compose ps でコンテナを確認し
docker-compose exec web bashでコンテナに入る

rails db:create #データベースを接続する
　このままやるとエラーが出るので、configフォルダ内のdatabase.ymlを書き換える

default: &default
  adapter: postgresql
  encoding: unicode
  host: db
  user: postgres
  port: 5432
  password: <%= ENV.fetch("DATABASE_PASSWORD")%> #パスワードには環境変数を使用する
  pool: <%= ENV.fetch("RAILS_MAX_THREADS") { 5 } %>
  timeout: 5000

このあとdocker-compose.ymlを変更する

【reilsのwebアプリを作成する】
docker-compose up -d
docker-compose exec web bash
rails db:create
rails g scaffold product name:string price:integer vendor:string
rails db:migrate
rails s -b 0.0.0.0
⇒ localhost:3000 にアクセス
　 http://localhost:3000/products で登録画面


14.CICDパイプライン
【Githubのレポジトリ作成】
Githubにレポジトリを作成し、gitbashを起動

git config user.name "Nakamukai1"
git config user.email "nakamukaiya@gmail.com" で設定

git config user.name #設定を確認
git config user.email 

#originにurlを指定
git remote add origin https://github.com/Nakamukai1/product-register.git

git add . 
git commit -m 'first commit' #-mでメッセージを入力
git push origin master #originのリモートリポジトリのmasterにプッシュする

【Railsのテストを実行】
docker-compose ps でupが無ければdocker-compose up -d
docker-compose exec web bash

rails test でテストを実行


【Travis CIのビルドを実行する】
git add .
git commit -m 'update docker compose'
git push origin master

【Herokuに登録する】

【.travis.ymlにHerokuへのデプロイを記述する】